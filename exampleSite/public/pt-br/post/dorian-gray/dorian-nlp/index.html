<!DOCTYPE html>
<html lang="pt-br" data-theme=""><head>
    <title>The Picture of Dorian Gray · Jane Doe</title>
    <meta charset="utf-8">
    
    <meta name="generator" content="Hugo 0.110.0"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
    <meta name="description" content="Call me Jane">
    
    
    
    <link rel="stylesheet" type="text/css" href="/css/style.min.81d1dc63576837a854e239c7a9f901085c1b106bffd71d0429f0282dea80e8a7.css" integrity="sha256-gdHcY1doN6hU4jnHqfkBCFwbEGv/1x0EKfAoLeqA6Kc=" crossorigin="anonymous" type="text/css">
    
    
    
    <link rel="stylesheet" type="text/css" href="/css/fonts.d5b213a8a0d81c895406ec26a5e679d5da547a46e1c4ebb0695ff83ae98025fb.css" integrity="sha256-1bITqKDYHIlUBuwmpeZ51dpUekbhxOuwaV/4OumAJfs=" crossorigin="anonymous">

    
    
    
    <script type="text/javascript" src="/js/anatole-header.min.a3fa728a9f57833a31dfb45c48caaf1e4890c8c97f07bd7133fc2359745edb5d.js" integrity="sha256-o/pyip9Xgzox37RcSMqvHkiQyMl/B71xM/wjWXRe210=" crossorigin="anonymous"></script>

    
    
    
    <script type="text/javascript" src="/js/sidebar-toc.min.788b639e2ec681549740b90b3b865d5f9e1789e3ca9c06ccc45d65655434c954.js" integrity="sha256-eItjni7GgVSXQLkLO4ZdX54XiePKnAbMxF1lZVQ0yVQ=" crossorigin="anonymous"></script>

    
    <link rel="shortcut icon" href="/favicons/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    <link rel="canonical" href="/pt-br/post/dorian-gray/dorian-nlp/">
    
    <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/images/site-feature-image.png"/>

<meta name="twitter:title" content="The Picture of Dorian Gray"/>
<meta name="twitter:description" content="Q"/>

</head><body>
        <div class="main">
            <div class="page-top">
    <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false" >
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    <ul class="nav" id="navMenu">
        
        
            
            <li><a  href="/pt-br/"  title="">Home</a></li>
        
            
            <li><a  href="/pt-br/post/"  title="">Blog</a></li>
        
            
            <li><a  href="/pt-br/about/"  title="">Sobre</a></li>
        
        <li class="grow"></li>
        
            
                <li><a href="/" title="en">en</a></li>
            
        
        <li>
            <a class="theme-switch" title="Switch Theme">
                <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>
            <div class="sidebar" id="sidebar">
    <div class="top-toc">
        <img src="/images/profile.jpg" alt="profile picture">
        
        <a href="/">I&#39;m Jane Doe</a>
    </div>
    
    <div class="middle-sidebar grow" id="middle-sidebar">
    
        <div class="title-toc" id="title-toc">
            <h6>Table of Contents</h6>
        </div>
        
        <nav id="TableOfContents">
  <ul>
    <li><a href="#bibliotecas">Bibliotecas</a></li>
    <li><a href="#funções-e-utilidades">Funções e Utilidades</a></li>
    <li><a href="#dados-e-pré-processamento">Dados e Pré-processamento</a>
      <ul>
        <li><a href="#vad-e-anew">VAD e ANEW</a>
          <ul>
            <li><a href="#afeto-e-emoção">Afeto e Emoção</a></li>
            <li><a href="#vad">VAD</a></li>
            <li><a href="#anew">ANEW</a></li>
          </ul>
        </li>
        <li><a href="#livro">Livro</a></li>
        <li><a href="#a-adaptação">A adaptação</a></li>
      </ul>
    </li>
    <li><a href="#analisando-o-livro">Analisando o Livro</a>
      <ul>
        <li><a href="#frequência-de-n-gramas">Frequência de n-gramas</a></li>
        <li><a href="#emoções-nos-parágrafos">Emoções nos Parágrafos</a></li>
        <li><a href="#sumarização">Sumarização</a></li>
      </ul>
    </li>
    <li><a href="#analisando-a-adaptação">Analisando a Adaptação</a>
      <ul>
        <li>
          <ul>
            <li><a href="#ilustrando-o-vad">Ilustrando o VAD</a></li>
          </ul>
        </li>
        <li><a href="#vad-do-personagem-ao-longo-da-adaptação">VAD do Personagem ao Longo da Adaptação</a></li>
      </ul>
    </li>
    <li><a href="#referências">Referências</a></li>
  </ul>
</nav>
    
    </div>

    <div class="footer">
        <ul class="social-links">
            
            <li>
                <a href="https://linkedin.com/" target="_blank" rel="noopener noreferrer" rel="me" aria-label="Linkedin">
                    <i class="fa fa-linkedin" aria-hidden="true"></i>
                </a>
            </li>
            
            <li>
                <a href="https://github.com/lucasVadilho/lucas-anatole/" target="_blank" rel="noopener noreferrer" rel="me" aria-label="GitHub">
                    <i class="fa fa-github" aria-hidden="true"></i>
                </a>
            </li>
            
            <li>
                <a href="https://www.instagram.com/" target="_blank" rel="noopener noreferrer" rel="me" aria-label="instagram">
                    <i class="fa fa-instagram" aria-hidden="true"></i>
                </a>
            </li>
            
            <li>
                <a href="mailto:lucas.vadilho@gmail.com" target="_blank" rel="noopener noreferrer" rel="me" aria-label="e-mail">
                    <i class="fa fa-envelope" aria-hidden="true"></i>
                </a>
            </li>
            
        </ul>

        <div class="by">by Jane Doe <b>·</b> 2023</div>
    </div>
</div>
            <div class="content">
<div class="post">
    <div class="post-title">
        <h1>The Picture of Dorian Gray</h1>
        
            <div class="post-header">
    <i class="fa fa-calendar-o"></i><span class="date">Sep 26, 2019</span>
    <i class="fa fa-clock-o"></i><span class="reading-time">14 minutes</span>
    


    

<div class="badges">

    
    
        <div class="badge">
            
            
            
            
            

            
            
            
                <a target="_blank" href="https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb"><img src="https://flat.badgen.net/badge/subject/status/pink?icon=github&amp;labelColor=ff0000&amp;" loading="lazy"/></a>
            
        </div>
    
        <div class="badge">
            
            
            
            
            

            
            
            
                <img src="https://badgen.net/badge/github/passing/pink?icon=github&amp;labelColor=ff0000&amp;label" loading="lazy"/>
            
        </div>
    
        <div class="badge">
            
            
            
            
            

            
            
            
                <img src="https://flat.badgen.net/badge/colab/Open%20in%20Colab/pink?icon=https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg&amp;&amp;label" loading="lazy"/>
            
        </div>
    

</div>
</div>
        
    </div>
    <div class="post-content">
        <p><a href="https://github.com"><img src="https://badgen.net/badge/icon/github?icon=github&amp;label" alt="GitHub"></a></p>
<p>O objetivo desse projeto é fazer uma análise exploratória e descritiva da história <em>The Picture of Dorian Gray</em>, de Oscar Wilde, focando nos aspectos emocionais dos personagens.</p>
<p>Para isso vamos olhar tanto para o livro quanto para uma adaptação do livro para uma peça de teatro.</p>
<p>As técnicas de PLN que vamos demonstrar são <strong>sumarização</strong> e <strong>extração de emoções</strong> (afeto, na realidade, mas explicamos melhor depois).</p>
<h2 id="bibliotecas">Bibliotecas</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>!pip install <span style="color:#ff79c6">--</span>upgrade wordcloud
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> wordcloud <span style="color:#ff79c6">import</span> WordCloud
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> pandas <span style="color:#ff79c6">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> numpy <span style="color:#ff79c6">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> matplotlib.pyplot <span style="color:#ff79c6">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> string
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">import</span> collections
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> PIL <span style="color:#ff79c6">import</span> Image
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#ff79c6">.</span>download(<span style="color:#f1fa8c">&#39;stopwords&#39;</span>)
</span></span><span style="display:flex;"><span>nltk<span style="color:#ff79c6">.</span>download(<span style="color:#f1fa8c">&#39;punkt&#39;</span>)
</span></span><span style="display:flex;"><span>nltk<span style="color:#ff79c6">.</span>download(<span style="color:#f1fa8c">&#39;wordnet&#39;</span>)
</span></span></code></pre></div><h2 id="funções-e-utilidades">Funções e Utilidades</h2>
<pre tabindex="0"><code>tokenize = nltk.word_tokenize

lemmatize = nltk.stem.WordNetLemmatizer().lemmatize

stopwords = nltk.corpus.stopwords.words(&#39;english&#39;)
stopwords.remove(&#39;no&#39;)
stopwords.remove(&#39;not&#39;)

punctuation = string.punctuation

artefacts = [&#34;``&#34;, &#34;&#39;&#39;&#34;, &#34;--&#34;, &#34;&#39;s&#34;, &#34;’&#34;, &#34;n&#39;t&#34;]

def preprocess(txt):
    txt = txt.lower()

    return [lemmatize(token) for token
             in tokenize(txt)
             if token not in stopwords and
                token not in punctuation and
                token not in artefacts]

def createFreqDict(words):
    count = collections.Counter(token for token in words)
    return dict(count)

def drawWordCloud(tokens, title, maskPath = None):
    mask = np.array(Image.open(maskPath)) if maskPath else None

    wc = WordCloud(width = 400, height = 800, mask = mask, colormap = None) 
    # colormap por sentimento?
    # https://martinvonlupin.de/emosaic/
    
    wc.generate_from_frequencies(createFreqDict(tokens))
    
    wc.to_file(f&#39;{title}.png&#39;)

def plotVAD(rolling, original):
    f, (v, a, d) = plt.subplots(3, 1, sharex = True, sharey = False, figsize = (15, 15))

    v.set_title(&#34;Valence&#34;)
    v.plot(original.valence, color = &#39;dodgerblue&#39;, alpha = 0.25)
    v.plot(rolling.valence, color = &#39;dodgerblue&#39;)

    a.set_title(&#34;Arousal&#34;)
    a.plot(original.arousal, color = &#39;violet&#39;, alpha = 0.25)
    a.plot(rolling.arousal, color = &#39;violet&#39;)

    d.set_title(&#34;Dominance&#34;)
    d.plot(original.dominance, color = &#39;crimson&#39;, alpha = 0.25)
    d.plot(rolling.dominance, color = &#39;crimson&#39;)

def plotPlayVAD(rolling, original, title):
    f, (v, a, d) = plt.subplots(3, 1, sharex = True, sharey = False, figsize = (15, 15))

    idxLimit = original.groupby([&#39;act&#39;, &#39;scene&#39;]).index.agg(max).values
    actLimits = original[original[&#39;index&#39;].isin(idxLimit)].index

    f.suptitle(f&#34;{title}&#39;s VAD&#34;, fontsize = 16)

    v.set_title(&#34;Valence&#34;)
    v.plot(original.valence, color = &#39;dodgerblue&#39;, alpha = 0.25)
    v.plot(rolling.valence, color = &#39;dodgerblue&#39;)
    v.vlines(actLimits, 0, 1, linestyles = &#39;dashed&#39;, transform = v.get_xaxis_transform(), alpha = 0.5, label = &#34;act change&#34;)
    v.legend()

    a.set_title(&#34;Arousal&#34;)
    a.plot(original.arousal, color = &#39;violet&#39;, alpha = 0.25)
    a.plot(rolling.arousal, color = &#39;violet&#39;)
    a.vlines(actLimits, 0, 1, linestyles = &#39;dashed&#39;, transform = a.get_xaxis_transform(), alpha = 0.5)

    d.set_title(&#34;Dominance&#34;)
    d.plot(original.dominance, color = &#39;crimson&#39;, alpha = 0.25)
    d.plot(rolling.dominance, color = &#39;crimson&#39;)
    d.vlines(actLimits, 0, 1, linestyles = &#39;dashed&#39;, transform = d.get_xaxis_transform(), alpha = 0.5)
</code></pre><h2 id="dados-e-pré-processamento">Dados e Pré-processamento</h2>
<h3 id="vad-e-anew">VAD e ANEW</h3>
<h4 id="afeto-e-emoção">Afeto e Emoção</h4>
<p>Antes de entrar em detalhes do modelo VAD, vamos tentar diferenciar afeto de emoção.</p>
<p>De maneira simplificada, afeto está atrelado ao ao reconhecimento de como você está se sentindo, dado o que você esta experienciando no momento. Ele cobre e envolve tanto emoções quanto sentimentos. Por exemplo, o quão calmo ou agitado você está.</p>
<p>Já emoção é a classificação que damos a um estado afetivo, ela  é uma reação dirigida a alguma coisa ou alguém.</p>
<h4 id="vad">VAD</h4>
<p>O modelo VAD (<em>Valence-Arousal-Dominance</em>) tenta capturar o estado afetivo em três dimensões independentes. O eixo <em>Valence</em> representa a variação entre desagradável-agradável, o <em>Arousal</em> o quão intenso é a sensação e <em>Dominance</em> representa o quão submisso-dominante a pessoa se sente.</p>
<p>A imagem a seguir coloca as seis emoções de Ekman no espaço VAD.</p>
<p><img src="https://www.researchgate.net/profile/Sven_Buechel/publication/307512566/figure/fig2/AS:727675475873793@1550502761529/Positions-of-Ekmans-basic-emotions-within-the-emotional-space-spanned-by-the-Valence.png" alt=""></p>
<p>Imagem retirada de [2]</p>
<h4 id="anew">ANEW</h4>
<p>Em 1999, Bradley et al., publicaram o ANEW (<em>Affective Norms for English Words</em>), um conjunto de 1034 palavras e seus valores de VAD. Em 2013, Warriner et al, expandiram esse conjunto para quase 14000 palavras.</p>
<p>O dataset gerado nessa pesquisa pode ser encontrado nos materiais suplementares de [1], dele nós vamos extrair as colunas de média geral de <em>valence</em>, <em>arousal</em> e <em>dominance</em> e construir três dicionários, um para cada dimensão, para facilitar a manipulação.</p>
<p>É importante notar que as palavras estão na sua forma de <em>lemma</em> no ANEW.</p>
<pre tabindex="0"><code>anew = pd\
    .read_csv(&#39;BRM-emot-submit.csv&#39;, usecols = [&#39;Word&#39;, &#39;V.Mean.Sum&#39;, &#39;A.Mean.Sum&#39;, &#39;D.Mean.Sum&#39;])\
    .rename(columns = {&#39;Word&#39;: &#39;word&#39;,
             &#39;V.Mean.Sum&#39;: &#39;valence&#39;,
             &#39;A.Mean.Sum&#39;: &#39;arousal&#39;,
             &#39;D.Mean.Sum&#39;: &#39;dominance&#39;})

valence = {w: v for w, v in zip(anew.word, anew.valence)}
arousal = {w: v for w, v in zip(anew.word, anew.arousal)}
dominance = {w: v for w, v in zip(anew.word, anew.dominance)}
</code></pre><p>A função <code>getAnewScore</code> é responsável por calcular o valor de uma das dimensões do VAD normalizado pelo número de lemmas. Note que estamos ignorando lemas que não aparecem no dataset ANEW.</p>
<pre tabindex="0"><code>def getAnewScore(lemmas, dict):
    sum = 0
    nWords = 0

    for l in lemmas:
        try:
            sum += dict[l]
            nWords += 1
        except:
            continue

    return sum / nWords if nWords &gt; 0 else np.nan
</code></pre><h3 id="livro">Livro</h3>
<p>O livro, publicado em 1880, já está em dominio público e pode ser encontrado no <a href="http://www.gutenberg.org/cache/epub/174/pg174.txt">projeto gutenberg</a>.</p>
<p>No livro vamos observar aspectos mais gerais, fazendo uma <strong>análise exploratória</strong>, <strong>extração de emoções</strong> e <strong>sumarização</strong>.</p>
<p>O livro será processado da seguinte maneira:</p>
<ul>
<li>Remover informações de licença e prefácio</li>
<li>Separar em parágrafos</li>
<li>Guardar os parágrafos originais em <code>originalParagraphs</code></li>
<li>Pré-processar os parágrafos em <code>preprocessedParagraphs</code></li>
<li>Avaliar VAD em cada parágrafo</li>
<li>Jutar tudo em <code>dfBook</code></li>
<li>Criar uma lista com todos os lemas do livro em <code>bookLemmas</code></li>
</ul>
<pre tabindex="0"><code>rawBook = open(&#39;dorianGray.txt&#39;).read().split(&#39;\n&#39;)

lines = rawBook[93:8535] # Removendo informações de licença e prefácio

# Livro em parágrafos
book = []

for line in lines:
    if line == &#39;&#39;:
        book.append(&#39;&lt;paragrafo&gt;&#39;)
    else:
        book.append(line)

book = &#39; &#39;.join(book)

bookParagraphs = book.split(&#39;&lt;paragrafo&gt;&#39;)

originalParagraphs = [p for p in bookParagraphs if not(not preprocess(p))]

preprocessedParagraphs = [preprocess(p) for p in bookParagraphs]
preprocessedParagraphs = [p for p in preprocessedParagraphs if not(not p)]

valenceParagraps = [getAnewScore(p, valence) for p in preprocessedParagraphs]
arousalParagraps = [getAnewScore(p, arousal) for p in preprocessedParagraphs]
dominanceParagraps = [getAnewScore(p, dominance) for p in preprocessedParagraphs]

bookLemmas = [lemma for paragraph in preprocessedParagraphs for lemma in paragraph]
</code></pre><pre tabindex="0"><code>data = list(zip(originalParagraphs, preprocessedParagraphs, valenceParagraps, arousalParagraps, dominanceParagraps))
dfBook = pd.DataFrame(data, columns = [&#39;originalParagraph&#39;, &#39;preprocessedParagraph&#39;, &#39;valence&#39;, &#39;arousal&#39;, &#39;dominance&#39;])

dfBook.head()
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>originalParagraph</th>
      <th>preprocessedParagraph</th>
      <th>valence</th>
      <th>arousal</th>
      <th>dominance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CHAPTER 1</td>
      <td>[chapter, 1]</td>
      <td>5.70000</td>
      <td>3.860000</td>
      <td>6.210000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The studio was filled with the rich odour of ...</td>
      <td>[studio, filled, rich, odour, rose, light, sum...</td>
      <td>6.32000</td>
      <td>4.063125</td>
      <td>5.603125</td>
    </tr>
    <tr>
      <th>2</th>
      <td>From the corner of the divan of Persian saddl...</td>
      <td>[corner, divan, persian, saddle-bags, lying, s...</td>
      <td>5.41240</td>
      <td>3.956800</td>
      <td>5.346200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>In the centre of the room, clamped to an upri...</td>
      <td>[centre, room, clamped, upright, easel, stood,...</td>
      <td>5.78800</td>
      <td>4.017000</td>
      <td>5.561500</td>
    </tr>
    <tr>
      <th>4</th>
      <td>As the painter looked at the gracious and com...</td>
      <td>[painter, looked, gracious, comely, form, skil...</td>
      <td>6.21125</td>
      <td>4.348750</td>
      <td>6.095625</td>
    </tr>
  </tbody>
</table>
</div>
<h3 id="a-adaptação">A adaptação</h3>
<p>A adaptação para teatro, desenvolvida pelo grupo de produções teatrais Palkettostage, está disponível no <a href="https://www.manzoni.edu.it/2017/files/dorian_gb.pdf">site da instituição</a> e é de uso educacional livre.</p>
<p>Como na adaptação temos uma estrutura em atos e cenas, além das falas dos personagens serem identificadas, vamos fazer a <strong>extração de emoções</strong> e analisar como os personagens variam durante o livro.</p>
<p>Um arquivo <code>.csv</code> foi construído manualmente a partir do arquivo original da peça. Nesse arquivo cada linha contém uma fala de um personagem, no formato: <code>act</code>, <code>scene</code>, <code>character</code>, <code>text</code>.</p>
<p>Vamos enriquecer esse dataset preprocessando as falas e avaliando o VAD de cada fala.</p>
<pre tabindex="0"><code>dfPlay = pd.read_csv(&#39;play.csv&#39;)

dfPlay[&#39;lemmas&#39;] = [preprocess(line) for line in dfPlay.text]
dfPlay[&#39;valence&#39;] = [getAnewScore(lemmas, valence) for lemmas in dfPlay.lemmas]
dfPlay[&#39;arousal&#39;] = [getAnewScore(lemmas, arousal) for lemmas in dfPlay.lemmas]
dfPlay[&#39;dominance&#39;] = [getAnewScore(lemmas, dominance) for lemmas in dfPlay.lemmas]

dfPlay.head()
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>act</th>
      <th>scene</th>
      <th>character</th>
      <th>text</th>
      <th>lemmas</th>
      <th>valence</th>
      <th>arousal</th>
      <th>dominance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>Lord Henry</td>
      <td>It’s your best work yet, Basil, the best thing...</td>
      <td>[best, work, yet, basil, best, thing, ever, do...</td>
      <td>5.735000</td>
      <td>3.740000</td>
      <td>5.616667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>Basil</td>
      <td>I don’t think I shall send it anywhere.</td>
      <td>[think, shall, send, anywhere]</td>
      <td>6.240000</td>
      <td>3.566667</td>
      <td>6.110000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>Lord Henry</td>
      <td>Not send it anywhere? What strange types you a...</td>
      <td>[not, send, anywhere, strange, type, artist, a...</td>
      <td>6.025714</td>
      <td>3.935714</td>
      <td>5.647857</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>Basil</td>
      <td>I know you’ll laugh at me but I really can’t e...</td>
      <td>[know, laugh, really, exhibit, put, much, pain...</td>
      <td>6.428000</td>
      <td>4.490000</td>
      <td>6.528000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>Lord Henry</td>
      <td>Too much of yourself! My dear man, I really ca...</td>
      <td>[much, dear, man, really, see, resemblance, yo...</td>
      <td>6.188182</td>
      <td>3.700000</td>
      <td>5.667273</td>
    </tr>
  </tbody>
</table>
</div>
<h2 id="analisando-o-livro">Analisando o Livro</h2>
<h3 id="frequência-de-n-gramas">Frequência de n-gramas</h3>
<p>Construímos <em>word clouds</em> para o livro usando unigramas, bigramas e trigramas.</p>
<pre tabindex="0"><code>for i in range(1, 4):
    nGram = list(&#39; &#39;.join(ngram) for ngram in nltk.ngrams(bookLemmas, i))
    drawWordCloud(nGram, f&#39;{i}gramBook&#39;)
</code></pre><ul>
<li>Unigramas</li>
</ul>
<p><img src="https://i.imgur.com/WBmpnJT.png" alt=""></p>
<ul>
<li>Bigramas</li>
</ul>
<p><img src="https://i.imgur.com/5HU0tvX.png" alt=""></p>
<ul>
<li>Trigramas</li>
</ul>
<p><img src="https://i.imgur.com/BWaS6re.png" alt=""></p>
<h3 id="emoções-nos-parágrafos">Emoções nos Parágrafos</h3>
<p>Abaixo estamos demonstrando os máximos e mínimos de cada dimensão como uma maneira de explorar os extremos de VAD encontrados no livro.</p>
<pre tabindex="0"><code>#@title Controle
from tabulate import tabulate
from IPython import display

dimension = &#39;dominance&#39; #@param [&#39;valence&#39;, &#39;arousal&#39;, &#39;dominance&#39;]
nParagraphs = 5 #@param {type: &#34;slider&#34;, min: 1, max: 10, step: 1}

sorted = dfBook.sort_values(dimension, ascending = False).dropna()

table = tabulate(list(zip(sorted.originalParagraph.head(nParagraphs), sorted.originalParagraph.tail(nParagraphs))), headers=[&#39;Max&#39;, &#39;Min&#39;], tablefmt = &#39;html&#39;)
display.display(display.HTML(f&#39;&lt;h3&gt;{dimension}&lt;/h3&gt;&#39;))
display.display(display.HTML(table))
</code></pre><h3>dominance</h3>
<table>
<thead>
<tr><th>Max                                                                 </th><th>Min                                      </th></tr>
</thead>
<tbody>
<tr><td>&quot;Alan!  This is kind of you.  I thank you for coming.&quot;              </td><td>&quot;I was wrong.  It has destroyed me.&quot;     </td></tr>
<tr><td>&quot;I am glad of that.  But who drove him to it?  You, I should fancy.&quot;</td><td>&quot;We have carried their burden.&quot;          </td></tr>
<tr><td>&quot;I congratulate you.&quot;                                               </td><td>&quot;Yes, there is a gas-fire with asbestos.&quot;</td></tr>
<tr><td>&quot;I am very glad you didn&#x27;t, Harry.&quot;                                 </td><td>&quot;Decay fascinates me more.&quot;              </td></tr>
<tr><td>&quot;I trust you.&quot;                                                      </td><td>&quot;They were defeated.&quot;                    </td></tr>
</tbody>
</table>
<p>Na célula abaixo estamos plotando os dados brutos e uma média móvel das dimensões emocionais. O tamanho da janela da média móvel pode ser definido pelo <em>slider</em> abaixo, basta rodar a célula novamente para atualizar.</p>
<pre tabindex="0"><code>#@title Controle
windowSize = 16 #@param {type: &#34;slider&#34;, min: 0, max: 100, step: 1}

rollingBook = dfBook\
    .dropna()\
    .rolling(windowSize, center = True)\
    .mean()

plotVAD(rollingBook, dfBook.dropna())
</code></pre><p><img src="Dorian_Gray_24_0.png" alt="png"></p>
<h3 id="sumarização">Sumarização</h3>
<p>Para realizar a sumarização vamos nos utilizar de cadeias de Markov e do conceito de similaridade de cosenos.</p>
<p>A cadeia de Markov é um modelo que descreve a probabilidade de transição entre dois estados. Vamos modelar nosso livro como uma cadeia de Markov da seguinte maneira: cada parágrafo é um nó e a probabilidade de transição entre os parágrafos é proporcional à similaridade de cosenos dos dois parágrafos.</p>
<!--![](https://miro.medium.com/max/875/1*j2V9mzy8EWEYsY-1clAM_w.png)-->
<p>Após a criação da matriz de transição, nós fazemos o processo de obter a matriz estacionária, que basicamente é a aplicação da matriz de transição nela mesma até a convergência dos valores.</p>
<p>Com isso extraímos a probabilidade de convergir para aquele determinado estado (parágrafo, no nosso caso). A sumarização do livro é então definida como os $n$ parágrafos com maior probabilidade na convergência.</p>
<pre tabindex="0"><code>def cosineSimilarity(p1, p2):
    # Os exemplos que encontrei criam os vetores no nível dos parágrafos que vamos comparar
    # faz sentido, pois usar todo o conjunto só diminuiria a similaridade geral
    v1 = []
    v2 = []
    for lemma in sorted(set(p1 + p2)):
        v1.append(1) if lemma in p1 else v1.append(0)
        v2.append(1) if lemma in p2 else v2.append(0)

    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

def transMatrix(paragraphs):
    n = len(paragraphs)
    matrix = np.zeros((n, n))

    for i in range(n):
        for j in range(i, n): # A matrix é simétrica
            matrix[i][j] = cosineSimilarity(paragraphs[i], paragraphs[j])

    # Passos desnecessários para o resultado
    # mas para ser uma matriz de transição, e poder falar de probabilidade, precisamos disso
    matrix = matrix / matrix.sum(axis = 0)
    matrix = (matrix + matrix.T) / 2

    return matrix

def getStationaryProbabilities(transMatrix):
    # Source
    # http://people.duke.edu/~ccc14/sta-663-2016/homework/Homework02_Solutions.html#Part-3:-Option-2:-Using-numpy.linalg-with-transpose-to-get-the-left-eigenvectors

    P = transMatrix/np.sum(transMatrix, 1)[:, np.newaxis]
    P5000 = np.linalg.matrix_power(P, 5000)
    P5001 = np.dot(P5000, P)

    # check that P500 is stationary
    np.testing.assert_allclose(P5000, P5001)

    return P5001

def printSummary(stationaryMatrix, nParagraphs = 5, verbose = False):
    from IPython import display
    
    pIdx = (-stationaryMatrix[0]).argsort()[:nParagraphs]

    summary = &#39;&lt;h3&gt;Summary of The Picture of Dorian Gray&lt;/h3&gt;&#39;
    for idx in pIdx:
        summary += f&#39;&lt;p&gt;{originalParagraphs[idx]}&lt;/p&gt;&#39;

        if verbose:
            print(f&#39;Paragraph tokens: {bookParagraphs[idx]}&#39;)
            print(f&#39;Original paragraph: {originalParagraphs[idx]}&#39;)

    display.display(display.HTML(summary))
</code></pre><pre tabindex="0"><code># Não está otimizado, então demora um pouco
# trans = transMatrix(preprocessedParagraphs)
# stationary = getStationaryProbabilities(trans)

# np.savetxt(&#34;transMatrix.csv&#34;, trans, delimiter = &#34;,&#34;)
# np.savetxt(&#34;stationary.csv&#34;, stationary, delimiter = &#34;,&#34;)
</code></pre><pre tabindex="0"><code>stationary = np.loadtxt(&#39;stationary.csv&#39;, delimiter = &#39;,&#39;)

printSummary(stationary)
</code></pre><h3>Summary of The Picture of Dorian Gray</h3><p> "It is your best work, Basil, the best thing you have ever done," said Lord Henry languidly.  "You must certainly send it next year to the Grosvenor.  The Academy is too large and too vulgar.  Whenever I have gone there, there have been either so many people that I have not been able to see the pictures, which was dreadful, or so many pictures that I have not been able to see the people, which was worse.  The Grosvenor is really the only place." </p><p> "Dorian Gray?  Is that his name?" asked Lord Henry, walking across the studio towards Basil Hallward. </p><p> "Not at all," answered Lord Henry, "not at all, my dear Basil.  You seem to forget that I am married, and the one charm of marriage is that it makes a life of deception absolutely necessary for both parties.  I never know where my wife is, and my wife never knows what I am doing. When we meet--we do meet occasionally, when we dine out together, or go down to the Duke's--we tell each other the most absurd stories with the most serious faces.  My wife is very good at it--much better, in fact, than I am.  She never gets confused over her dates, and I always do. But when she does find me out, she makes no row at all.  I sometimes wish she would; but she merely laughs at me." </p><p> "Too much of yourself in it! Upon my word, Basil, I didn't know you were so vain; and I really can't see any resemblance between you, with your rugged strong face and your coal-black hair, and this young Adonis, who looks as if he was made out of ivory and rose-leaves. Why, my dear Basil, he is a Narcissus, and you--well, of course you have an intellectual expression and all that.  But beauty, real beauty, ends where an intellectual expression begins.  Intellect is in itself a mode of exaggeration, and destroys the harmony of any face.  The moment one sits down to think, one becomes all nose, or all forehead, or something horrid.  Look at the successful men in any of the learned professions. How perfectly hideous they are!  Except, of course, in the Church.  But then in the Church they don't think.  A bishop keeps on saying at the age of eighty what he was told to say when he was a boy of eighteen, and as a natural consequence he always looks absolutely delightful. Your mysterious young friend, whose name you have never told me, but whose picture really fascinates me, never thinks.  I feel quite sure of that.  He is some brainless beautiful creature who should be always here in winter when we have no flowers to look at, and always here in summer when we want something to chill our intelligence.  Don't flatter yourself, Basil:  you are not in the least like him." </p><p> Lord Henry elevated his eyebrows and looked at him in amazement through the thin blue wreaths of smoke that curled up in such fanciful whorls from his heavy, opium-tainted cigarette.  "Not send it anywhere?  My dear fellow, why?  Have you any reason?  What odd chaps you painters are!  You do anything in the world to gain a reputation.  As soon as you have one, you seem to want to throw it away.  It is silly of you, for there is only one thing in the world worse than being talked about, and that is not being talked about.  A portrait like this would set you far above all the young men in England, and make the old men quite jealous, if old men are ever capable of any emotion." </p>
<h2 id="analisando-a-adaptação">Analisando a Adaptação</h2>
<h4 id="ilustrando-o-vad">Ilustrando o VAD</h4>
<p>Agora que vamos analisar em nível de frases de personagens, podemos ilustrar melhor os conceitos do modelo VAD nas falas dos personagens. Faremos isso pegando as frases extremas em cada dimensão.</p>
<pre tabindex="0"><code>#@title Controle
from tabulate import tabulate
from IPython import display

character = &#39;Dorian&#39; #@param [&#39;Alan&#39;, &#39;Basil&#39;, &#39;Butler&#39;, &#39;Dorian&#39;, &#39;Duchess&#39;, &#39;Geoffrey&#39;, &#39;Head Keeper&#39;, &#39;Hetty&#39;, &#39;James&#39;, &#39;Lord Henry&#39;, &#39;Mr. Isaacs&#39;, &#39;Opium Seller&#39;, &#39;Sybil&#39;]
dimension = &#39;dominance&#39; #@param [&#39;valence&#39;, &#39;arousal&#39;, &#39;dominance&#39;]
nParagraphs = 5 #@param {type: &#34;slider&#34;, min: 1, max: 10, step: 1}

sorted = dfPlay[dfPlay.character == character].sort_values(dimension, ascending = False).dropna()

table = tabulate(list(zip(sorted.text.head(nParagraphs), sorted.text.tail(nParagraphs))), headers=[&#39;Max&#39;, &#39;Min&#39;], tablefmt = &#39;html&#39;)
display.display(display.HTML(f&#39;&lt;h3&gt;{character}\&#39;s {dimension}&lt;/h3&gt;&#39;))
display.display(display.HTML(table))
</code></pre><h3>Dorian's dominance</h3>
<table>
<thead>
<tr><th>Max                                                     </th><th>Min                                                                                           </th></tr>
</thead>
<tbody>
<tr><td>Am I safe here, Harry?                                  </td><td>What time is it, Victor?                                                                      </td></tr>
<tr><td>That will be all, thank you Victor.                     </td><td>Harry, you are horrible! Of course, she cried, and all that. But there is no disgrace for her.</td></tr>
<tr><td>I have an appointment somewhere else.                   </td><td>It’s too late. Too late! Too late! Far too late!                                              </td></tr>
<tr><td>Hetty, will you give me the pleasure of walking with me?</td><td>It’s a bad omen, Harry. A very bad omen.                                                      </td></tr>
<tr><td>I wonder, have you seen…                                </td><td>I beg you, Alan.                                                                              </td></tr>
</tbody>
</table>
<p>Dos valores extremos podemos notar que eles representam bem o conceito. Com excessão de alguns que não parecem muito representativo do conceito. Acredito que isso se deva a dois fatores extremamante importantes:</p>
<ul>
<li>Pontuação como &ldquo;?&rdquo; e &ldquo;!&rdquo;</li>
<li>Negações</li>
</ul>
<p>Para trabalhos futuros devemos analisar mais profundamente as frases, levando em conta pontuações, por exemplo amplificar o valor caso uma exclamação seja encontrada.</p>
<p>Além disso, não estamos levando em conta negações nas frases, uma correção possível seria &ldquo;inverter&rdquo; o valor da dimensão caso uma negação esteja na sua vizinhança. Em [3], temos a sugestão de atualizar <em>valence</em> para $5 – (V – 5)$ caso uma negação esteja próxima.</p>
<h3 id="vad-do-personagem-ao-longo-da-adaptação">VAD do Personagem ao Longo da Adaptação</h3>
<p>Escolher o tamanho da janela* e personagem.</p>
<p>* As janelas são menores aqui devido a quantidade de falas de cada personagem.</p>
<pre tabindex="0"><code>#@title Controle
windowSize = 2 #@param {type: &#34;slider&#34;, min: 0, max: 10, step: 1}
character = &#39;Dorian&#39; #@param [&#39;Alan&#39;, &#39;Basil&#39;, &#39;Butler&#39;, &#39;Dorian&#39;, &#39;Duchess&#39;, &#39;Geoffrey&#39;, &#39;Head Keeper&#39;, &#39;Hetty&#39;, &#39;James&#39;, &#39;Lord Henry&#39;, &#39;Mr. Isaacs&#39;, &#39;Opium Seller&#39;, &#39;Sybil&#39;]

characterLines = dfPlay[dfPlay.character == character]\
    .dropna()\
    .reset_index()

rollingPlay = characterLines\
    .dropna()\
    .rolling(windowSize, center = True)\
    .mean()

plotPlayVAD(rollingPlay, characterLines, character)
</code></pre><p><img src="Dorian_Gray_34_0.png" alt="png"></p>
<h2 id="referências">Referências</h2>
<p>[1] Warriner, A.B., Kuperman, V. &amp; Brysbaert, M. Norms of valence, arousal, and dominance for 13,915 English lemmas. Behav Res 45, 1191–1207 (2013). <a href="https://doi.org/10.3758/s13428-012-0314-x">https://doi.org/10.3758/s13428-012-0314-x</a></p>
<p>[2] Buechel, Sven &amp; Hahn, Udo. (2016). Emotion Analysis as a Regression Problem — Dimensional Models and Their Implications on Emotion Representation and Metrical Evaluation. 10.3233/978-1-61499-672-9-1114.</p>
<p>[3] Atmaja B. T., Text Emotion Recognition using Affective
Dictionary/Lexicon <a href="https://github.com/bagustris/text-vad/blob/master/report_minor3.pdf">https://github.com/bagustris/text-vad/blob/master/report_minor3.pdf</a></p>
    </div>
    <div class="post-footer">
        <div class="info">
            
            
        </div>
    </div>
    
        
    
</div>

                <div class="grow"></div>
                <div class="built-with">
    Built with <a>Hugo</a> <b>·</b> Using the <a>anatole</a> theme
</div>
            </div>
        </div>
        </body>


<link defer href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"
    integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

<script type="text/javascript" src="/js/medium-zoom.min.e1c6918cbaa90022a5612f0bd71c7bf3be6d036614c5729cebfe14f7b91fa4bc.js" integrity="sha256-4caRjLqpACKlYS8L1xx7875tA2YUxXKc6/4U97kfpLw=" crossorigin="anonymous"></script><script type="text/javascript">
            
            
            window.MathJax = {
                tex: {
                    inlineMath: [['$', '$'], ['\\(', '\\)']],
                    displayMath: [['$$','$$'], ['\\[', '\\]']]
                },
                svg: {
                    scale: 1.25,
                }
            };
        </script><script defer type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.1.0/es5/tex-mml-svg.min.js" integrity="sha512-/mL9Gs6E5Bz6NtPOr9eY&#43;T8IIdJbo2JL3TudApzFFelwBXEc3TeFLU6kPq122TJROv7jkktuBRkz5h8vGzrsyA==" crossorigin="anonymous"></script></html>
    </body>
</html>